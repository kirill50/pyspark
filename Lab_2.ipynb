{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 2 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as sf\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.sql.types import IntegerType, StringType, ArrayType, MapType, DoubleType\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "spark.conf.set('spark.sql.execution.arrow.enabled', 'false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-de-master-5.newprolab.com:4045\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f846563bb00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses = spark.read.json('/labs/slaba02/DO_record_per_line.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>desc</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>name</th>\n",
       "      <th>provider</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/business_management|6/economics_finance</td>\n",
       "      <td>This course introduces the basic financial sta...</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>Accounting Cycle: The Foundation of Business M...</td>\n",
       "      <td>Canvas Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/law</td>\n",
       "      <td>This online course will introduce you to Ameri...</td>\n",
       "      <td>5</td>\n",
       "      <td>en</td>\n",
       "      <td>American Counter Terrorism Law</td>\n",
       "      <td>Canvas Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/computer_science|15/mathematics_statistics_a...</td>\n",
       "      <td>This course is taught in French Vous voulez co...</td>\n",
       "      <td>6</td>\n",
       "      <td>fr</td>\n",
       "      <td>Arithmétique: en route pour la cryptographie</td>\n",
       "      <td>Canvas Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14/social_sciences</td>\n",
       "      <td>We live in a digitally connected world. The wa...</td>\n",
       "      <td>7</td>\n",
       "      <td>en</td>\n",
       "      <td>Becoming a Dynamic Educator</td>\n",
       "      <td>Canvas Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/biology_life_sciences</td>\n",
       "      <td>This self-paced course is designed to show tha...</td>\n",
       "      <td>8</td>\n",
       "      <td>en</td>\n",
       "      <td>Bioethics</td>\n",
       "      <td>Canvas Network</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 cat  \\\n",
       "0          3/business_management|6/economics_finance   \n",
       "1                                             11/law   \n",
       "2  5/computer_science|15/mathematics_statistics_a...   \n",
       "3                                 14/social_sciences   \n",
       "4                            2/biology_life_sciences   \n",
       "\n",
       "                                                desc  id lang  \\\n",
       "0  This course introduces the basic financial sta...   4   en   \n",
       "1  This online course will introduce you to Ameri...   5   en   \n",
       "2  This course is taught in French Vous voulez co...   6   fr   \n",
       "3  We live in a digitally connected world. The wa...   7   en   \n",
       "4  This self-paced course is designed to show tha...   8   en   \n",
       "\n",
       "                                                name        provider  \n",
       "0  Accounting Cycle: The Foundation of Business M...  Canvas Network  \n",
       "1                     American Counter Terrorism Law  Canvas Network  \n",
       "2       Arithmétique: en route pour la cryptographie  Canvas Network  \n",
       "3                        Becoming a Dynamic Educator  Canvas Network  \n",
       "4                                          Bioethics  Canvas Network  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "courses.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses = courses.select('id', 'lang','desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokinizer = Tokenizer(inputCol='desc', outputCol='words')\n",
    "courses = tokinizer.transform(courses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to clean list of words\n",
    "def clear_list(words_list):\n",
    "    regex = re.compile('[\\w\\d]{2,}', re.U)\n",
    "    filtered = [i for i in words_list if regex.match(i)]\n",
    "    return filtered\n",
    "\n",
    "clear_list_udf = sf.udf(clear_list, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses = courses.withColumn(\"clear_words\",clear_list_udf(sf.col(\"words\")))\n",
    "courses = courses.select('id', 'lang','clear_words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28153"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get term frequency vector through HashingTF (TF)\n",
    "ht = HashingTF(inputCol=\"clear_words\", outputCol=\"word_vector_freq\", numFeatures=10000) \n",
    "tf = ht.transform(courses)\n",
    "\n",
    "# Carrying out Inverse Document Frequency on the TF data\n",
    "idf=IDF(inputCol=\"word_vector_freq\", outputCol=\"tfidf_feature\")\n",
    "idfModel = idf.fit(tf)\n",
    "courses_result = idfModel.transform(tf)\n",
    "\n",
    "courses_result.cache().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_result = courses_result.select('id', 'lang', 'tfidf_feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------------------+\n",
      "| id|lang|       tfidf_feature|\n",
      "+---+----+--------------------+\n",
      "|  4|  en|(10000,[36,42,63,...|\n",
      "|  5|  en|(10000,[32,222,29...|\n",
      "|  6|  fr|(10000,[30,41,246...|\n",
      "|  7|  en|(10000,[493,572,7...|\n",
      "|  8|  en|(10000,[32,65,115...|\n",
      "|  9|  en|(10000,[56,91,268...|\n",
      "| 10|  en|(10000,[1045,1263...|\n",
      "| 11|  en|(10000,[87,157,57...|\n",
      "| 12|  en|(10000,[161,164,4...|\n",
      "| 13|  en|(10000,[26,1072,1...|\n",
      "| 14|  en|(10000,[145,234,3...|\n",
      "| 15|  en|(10000,[32,65,77,...|\n",
      "| 16|  en|(10000,[32,273,30...|\n",
      "| 17|  en|(10000,[695,1420,...|\n",
      "| 18|  en|(10000,[307,316,3...|\n",
      "| 19|  en|(10000,[572,768,8...|\n",
      "| 20|  en|(10000,[91,273,31...|\n",
      "| 21|  en|(10000,[148,157,1...|\n",
      "| 22|  en|(10000,[128,177,4...|\n",
      "| 23|  en|(10000,[91,332,52...|\n",
      "+---+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "courses_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses2predict = courses_result.filter(\n",
    "    sf.col('id').isin([23126, 21617, 16627, 11556, 16704, 13702]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## join 2 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = courses2predict.select(sf.col('id').alias('id2predict'),\n",
    "              sf.col('tfidf_feature').alias('tfidf_feature2predict'),\n",
    "              'lang').join(courses_result, on='lang', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df.id2predict != df.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------------------+-----+--------------------+\n",
      "|lang|id2predict|tfidf_feature2predict|   id|       tfidf_feature|\n",
      "+----+----------+---------------------+-----+--------------------+\n",
      "|  en|     21617| (10000,[213,360,4...|16308|(10000,[505,1387,...|\n",
      "|  en|     21617| (10000,[213,360,4...|16309|(10000,[128,996,1...|\n",
      "|  en|     21617| (10000,[213,360,4...|16310|(10000,[505,706,1...|\n",
      "|  en|     21617| (10000,[213,360,4...|16311|(10000,[240,281,1...|\n",
      "|  en|     21617| (10000,[213,360,4...|16312|(10000,[1036,1239...|\n",
      "|  en|     21617| (10000,[213,360,4...|16313|(10000,[304,1387,...|\n",
      "|  en|     21617| (10000,[213,360,4...|16314|(10000,[505,1186,...|\n",
      "|  en|     21617| (10000,[213,360,4...|16315|(10000,[71,2286,2...|\n",
      "|  en|     21617| (10000,[213,360,4...|16316|(10000,[68,71,221...|\n",
      "|  en|     21617| (10000,[213,360,4...|16317|(10000,[542,1387,...|\n",
      "|  en|     21617| (10000,[213,360,4...|16318|(10000,[524,1187,...|\n",
      "|  en|     21617| (10000,[213,360,4...|16319|(10000,[163,1239,...|\n",
      "|  en|     21617| (10000,[213,360,4...|16320|(10000,[1036,1425...|\n",
      "|  en|     21617| (10000,[213,360,4...|16321|(10000,[1036,1425...|\n",
      "|  en|     21617| (10000,[213,360,4...|16322|(10000,[17,56,374...|\n",
      "|  en|     21617| (10000,[213,360,4...|16323|(10000,[173,855,1...|\n",
      "|  en|     21617| (10000,[213,360,4...|16324|(10000,[129,763,1...|\n",
      "|  en|     21617| (10000,[213,360,4...|16325|(10000,[855,885,1...|\n",
      "|  en|     21617| (10000,[213,360,4...|16326|(10000,[534,1697,...|\n",
      "|  en|     21617| (10000,[213,360,4...|16327|(10000,[1263,1355...|\n",
      "+----+----------+---------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_cos(v1, v2):\n",
    "    cosine_angle = float(np.dot(v1,v2)/np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    return cosine_angle\n",
    "\n",
    "sim_cos_udf = sf.udf(sim_cos, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_cos = df.withColumn('cos', sim_cos_udf('tfidf_feature2predict', 'tfidf_feature'))                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df_cos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "\n",
    "window = Window.partitionBy(final_df_cos['id2predict']).orderBy(final_df_cos['cos'].desc())\n",
    "\n",
    "top_ten = final_df_cos.select('*', sf.rank().over(window).alias('rank')).filter(sf.col('rank') <= 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_ten.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten = top_ten.select('lang', 'id2predict', 'id', 'cos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten = top_ten.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten_list = top_ten.groupby('id2predict')['id'].apply(list).reset_index(name='id_lists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten_list.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten_list_dict = dict(zip(top_ten_list.id2predict,top_ten_list.id_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object = json.dumps(top_ten_list_dict, indent = 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lab02.json\", \"w\") as outfile:\n",
    "    json.dump(top_ten_list_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
